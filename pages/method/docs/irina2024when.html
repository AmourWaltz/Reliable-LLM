<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="viewport" content="width=device-width, minimal-ui, initial-scale=1, viewport-fit=cover">
        <title>When Quantization Affects Confidence of Large Language Models?</title>
        <link rel="icon" type="image/png" href="assets/images/favicon.png">
        <link href="assets/css/main.css" rel="stylesheet">
    </head>
    <body>
        <h1 id="when-quantization-affects-confidence-of-large-language-models">When Quantization Affects Confidence of Large Language Models?</h1>
<p>[<a href="https://arxiv.org/abs/2405.00632">Link</a>]</p>
<h2 id="motivation">Motivation</h2>
<ul>
<li>Existing works have indicated that quantization might compromise performance and exacerbate biases in LLMs.</li>
</ul>
<h2 id="contributions">Contributions</h2>
<ul>
<li>Investigate how quantization with GPTQ influences the calibration and confidence of LLMs.</li>
<li>Assess the confidence alignment between compressed and full LLMs at scale.</li>
<li>Explain the quantization loss from the initial confidence perspective.</li>
</ul>
<h2 id="methodology">Methodology</h2>
<h3 id="quantization">Quantization</h3>
<p>Post-training quantization method known as GPTQ: Employs iterative layer-wise weight quantization based on the input data, providing several benefits compared to other quantization methods: minimized weight approximation error, support for serialization across various bit configurations, and significantly accelerated inference using GPUs.</p>
<h2 id="experiments">Experiments</h2>
<h3 id="models">Models</h3>
<ul>
<li>BLOOM, OPT, Mistral-7B, LLaMA-7B.</li>
</ul>
<h3 id="datasets">Datasets</h3>
<p><strong>Commonsense reasoning</strong></p>
<ul>
<li>Question answering involving reading comprehension (BOOLQ);</li>
<li>Natural text entailment (XSTORYEN,H ELLASWAG);</li>
<li>Science fact knowledge (ARC,OBQA );</li>
<li>Physical commonsense (PIQA).</li>
</ul>
<h3 id="metrics">Metrics</h3>
<ul>
<li>Accu, CE, ECE, ACE.</li>
</ul>
<h3 id="results">Results</h3>
<ul>
<li><strong>Calibration Impact</strong>: Quantization amplifies the pre-existing high calibration error present in the models before compression across different models and benchmarks.</li>
<li><strong>Confidence Impact</strong>: An amplification in the variance across answers, reflecting increased uncertainty in answer selection due to quantization.</li>
<li><strong>Identifying Cases of Confidence Change</strong>: Quantization predominantly influences the confidence of samples where the original model exhibited lower confidence levels.</li>
<li><strong>Jensen-Shannon Distances</strong>: Distances between original and compressed decrease as the model size scales up.</li>
</ul>
<h2 id="findings">Findings</h2>
<ul>
<li>Reveal that quantization with GPTQ to 4-bit results in a decrease in confidence regarding true labels, with varying impacts observed among different language models.</li>
<li>Observe fluctuations in the impact on confidence across different scales.</li>
<li>Propose an explanation for quantization loss based on confidence levels, indicating that quantization disproportionately affects samples where the full model exhibited low confidence levels in the first place.</li>
</ul>

    </body>
</html>
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="viewport" content="width=device-width, minimal-ui, initial-scale=1, viewport-fit=cover">
        <title>Few-Shot Recalibration of Language Models</title>
        <link rel="icon" type="image/png" href="assets/images/favicon.png">
        <link href="assets/css/main.css" rel="stylesheet">
    </head>
    <body>
        <h1 id="few-shot-recalibration-of-language-models">Few-Shot Recalibration of Language Models</h1>
<p>[<a href="https://arxiv.org/abs/2403.18286">Link</a>]</p>
<h2 id="motivation">Motivation</h2>
<p>While LMs may appear well-calibrated over broad distributions, this often hides significant miscalibration within narrower slices (e.g., systemic overconfidence in math can balance out systemic under-confidence in history, yielding perfect calibration in aggregate).</p>
<p>This miscalibration problem is hidden for the combined distribution because overconfidence in some domains cancels out underconfidence in others.</p>
<p><img src="../imgs/li2024fewshot/image.png" alt="alt text"></p>
<p><img src="../imgs/li2024fewshot/image-2.png" alt="alt text"></p>
<h2 id="methodology">Methodology</h2>
<h3 id="few-shot-slice-specific-recalibration">Few-Shot Slice-Specific Recalibration</h3>
<ol>
<li>Train a separate recalibration model that takes a few unlabeled examples as input and outputs a curve that maps the LM’s confidence scores to slice-specific estimates of precision.</li>
</ol>
<h3 id="parametrizing-f-predicting-precision-curves-vs-calibration-curves">Parametrizing f: Predicting Precision Curves vs. Calibration Curves</h3>
<ol>
<li>Define f to be the precision curve, which maps confidence thresholds to precision scores.</li>
<li>This flexibility of the precision curve allows us to accomplish a variety of downstream goals such as reducing calibration error, finding optimal confidence thresholds for desired precision.</li>
<li>Choose precision curves as our calibrator’s prediction target</li>
</ol>
<h3 id="binning-steps-for-calibration-curve">Binning Steps for Calibration Curve</h3>
<ol>
<li>The binning design, where scores can either be grouped into equally-spaced bins with equal interval ranges, or equally-sized bins with an equal number of examples per bin. </li>
<li>The number of bins such that scores can be grouped into a large number of bins each containing a small number of examples, or a small number of bins each containing many examples.</li>
</ol>
<h3 id="synthetic-data-construction">Synthetic Data Construction</h3>
<h3 id="training-the-few-shot-recalibrator">Training the Few-Shot Recalibrator</h3>
<p>Predicting a higher precision score than the ground-truth means the recalibrator believes the model correctly answers more questions than it actually can, and the confidence threshold does not trigger abstention when it should.</p>
<p><img src="../imgs/li2024fewshot/image-1.png" alt="alt text"></p>
<h2 id="experiments">Experiments</h2>
<h3 id="models">Models</h3>
<ul>
<li>LLaMA-65B and PaLM2-Large.</li>
</ul>
<h3 id="datasets">Datasets</h3>
<ul>
<li>MMLU and XNLI.</li>
</ul>
<h3 id="settings">Settings</h3>
<ul>
<li>Achieving Target Precision.</li>
<li>Reducing Calibration Error.</li>
</ul>
<h2 id="future-work">Future Work</h2>
<p>Future work should study few-shot recalibration for natural language generation tasks, to steer model generated text to be more or less conservative, as well as apply this approach to a broader set of models, including instruction-tuned and RLHF models, and multimodal settings.</p>

    </body>
</html>